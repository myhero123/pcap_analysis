{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e73eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcb9518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15176/1641415974.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Label[data['Label'] != 'BENIGN'] = 1\n",
      "/tmp/ipykernel_15176/1641415974.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Label[data['Label'] == 'BENIGN'] = 0\n"
     ]
    }
   ],
   "source": [
    "columns = ['Destination_Port', 'Flow_Duration', 'Total_Fwd_Packets',\n",
    "           'Total_Backward_Packets', 'Total_Length_of_Fwd_Packets',\n",
    "           'Total_Length_of_Bwd_Packets', 'Fwd_Packet_Length_Max',\n",
    "           'Fwd_Packet_Length_Min', 'Fwd_Packet_Length_Mean',\n",
    "           'Fwd_Packet_Length_Std', 'Bwd_Packet_Length_Max',\n",
    "           'Bwd_Packet_Length_Min', 'Bwd_Packet_Length_Mean',\n",
    "           'Bwd_Packet_Length_Std', 'Flow_Bytes/s', 'Flow_Packets/s',\n",
    "           'Flow_IAT_Mean', 'Flow_IAT_Std', 'Flow_IAT_Max', 'Flow_IAT_Min',\n",
    "           'Fwd_IAT_Total', 'Fwd_IAT_Mean', 'Fwd_IAT_Std', 'Fwd_IAT_Max',\n",
    "           'Fwd_IAT_Min', 'Bwd_IAT_Total', 'Bwd_IAT_Mean', 'Bwd_IAT_Std',\n",
    "           'Bwd_IAT_Max', 'Bwd_IAT_Min', 'Fwd_PSH_Flags', 'Bwd_PSH_Flags',\n",
    "           'Fwd_URG_Flags', 'Bwd_URG_Flags', 'Fwd_Header_Length',\n",
    "           'Bwd_Header_Length', 'Fwd_Packets/s', 'Bwd_Packets/s',\n",
    "           'Min_Packet_Length', 'Max_Packet_Length', 'Packet_Length_Mean',\n",
    "           'Packet _Length_Std', ' Packet_Length_Variance', 'FIN_Flag_Count',\n",
    "           'SYN_Flag_Count', 'RST_Flag_Count', 'PSH_Flag_Count',\n",
    "           'ACK_Flag_Count', 'URG_Flag_Count', 'CWE_Flag_Count',\n",
    "           'ECE_Flag_Count', 'Down/Up_Ratio', 'Average_Packet_Size',\n",
    "           'Avg_Fwd_Segment_Size', 'Avg_Bwd_Segment_Size',\n",
    "           'Fwd_Header_Length.1', 'Fwd_Avg_Bytes/Bulk', '_Fwd_Avg_Packets/Bulk',\n",
    "           'Fwd_Avg_Bulk_Rate', 'Bwd_Avg_Bytes/Bulk', 'Bwd_Avg_Packets/Bulk',\n",
    "           'Bwd_Avg_Bulk_Rate', 'Subflow_Fwd_Packets', 'Subflow_Fwd_Bytes',\n",
    "           'Subflow_Bwd_Packets', 'Subflow_Bwd_Bytes', 'Init_Win_bytes_forward',\n",
    "           'Init_Win_bytes_backward', 'act_data_pkt_fwd',\n",
    "           'min_seg_size_forward', 'Active_Mean', 'Active_Std', 'Active_Max',\n",
    "           'Active Min', 'Idle_Mean', 'Idle_Std', 'Idle_Max', 'Idle_Min',\n",
    "           'Label']\n",
    "\n",
    "csvfile = \"/root/data/fxg/csv\"\n",
    "all_scv_list = os.listdir(csvfile)\n",
    "for single_csv in all_scv_list:\n",
    "    single_data = pd.read_csv(os.path.join(csvfile, single_csv), header=1)\n",
    "    if single_csv == all_scv_list[0]:\n",
    "        data = single_data\n",
    "    else:\n",
    "        data = pd.concat([data, single_data], ignore_index=True)\n",
    "data.columns = columns\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.Label[data['Label'] != 'BENIGN'] = 1\n",
    "data.Label[data['Label'] == 'BENIGN'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71d07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #硬编码\n",
    "# encode=LabelEncoder()\n",
    "# encode.fit(col)\n",
    "# data['Label']=encode.transform(data['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32e44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Label'], axis=1)\n",
    "labelencoder_x=LabelEncoder()\n",
    "for i in columns[:-1]:\n",
    "      X[i]=labelencoder_x.fit_transform(X[i])\n",
    "y = data['Label'].astype(int)\n",
    "del data\n",
    "# 标准化\n",
    "transfer = MinMaxScaler(feature_range=(2, 3))\n",
    "X = transfer.fit_transform(X)\n",
    "\n",
    "# 降维\n",
    "transfer = VarianceThreshold(threshold=0.0)\n",
    "X = transfer.fit_transform(X)\n",
    "# 主成分分析\n",
    "transfer = PCA(n_components=0.9)\n",
    "X = transfer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=20)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c35924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.isnull().values==True]\n",
    "# data\n",
    "# transfer = MinMaxScaler(feature_range=(2, 3))\n",
    "# data = transfer.fit_transform(data[data.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6e7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNN] train...\n",
      "acc: 0.9994721240914444\n",
      "using time: 4.164442777633667 sec\n",
      "[[48587     8]\n",
      " [   18   641]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     48595\n",
      "           1       0.99      0.97      0.98       659\n",
      "\n",
      "    accuracy                           1.00     49254\n",
      "   macro avg       0.99      0.99      0.99     49254\n",
      "weighted avg       1.00      1.00      1.00     49254\n",
      "\n",
      "KNN-均方差为：\n",
      " 0.0005278759085556503\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def KNN(train_X, train_Y, test_X, test_Y):\n",
    "    print('[KNN] train...')\n",
    "    t1 = time.time()\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    model = knn.fit(train_X, train_Y)\n",
    "    y_hat = model.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, y_hat)\n",
    "    t2 = time.time()\n",
    "    print('acc:', acc)\n",
    "    print('using time:', t2 - t1, 'sec')\n",
    "    matrix = confusion_matrix(test_Y, y_hat)\n",
    "    print(matrix)\n",
    "    report = classification_report(test_Y, y_hat)\n",
    "    print(report)\n",
    "    error = mean_squared_error(test_Y, y_hat)\n",
    "    print(\"KNN-均方差为：\\n\", error)\n",
    "    print('-' * 20)\n",
    "    # plot_confusion_matrix(matrix, label, True, 'KNN Confusion matrix')\n",
    "KNN(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95494034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = KNeighborsClassifier(n_neighbors=3)\n",
    "# estimator.fit(X_train, y_train.astype(int))\n",
    "# classification_report(y_test, estimator.predict(X_test))\n",
    "# print(\"KNN classification_report==\\n\", classification_report(\n",
    "#     y_test, estimator.predict(X_test)))\n",
    "# error = mean_squared_error(y_test, estimator.predict(X_test))\n",
    "# print(\"KNN-均方差为：\\n\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd293e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# print(\"Neural Network\")\n",
    "# mlpc = MLPClassifier(hidden_layer_sizes=(11, 11, 11), max_iter=500)\n",
    "# mlpc.fit(X_train, y_train)\n",
    "# pred_mlpc = mlpc.predict(X_test)\n",
    "# print(\"Neural Network classification_report==\\n\",\n",
    "#       classification_report(y_test, pred_mlpc))\n",
    "# print(\"Neural Network confusion_matrix==\\n\",\n",
    "#       confusion_matrix(y_test, pred_mlpc))\n",
    "# error = mean_squared_error(y_test, pred_mlpc)\n",
    "# print(\"神经网络-均方误差为：\\n\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机深林\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RF(train_X, train_Y, test_X, test_Y):\n",
    "    print(\"Random Forest Classifier\")\n",
    "    t1 = time.time()\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(train_X, train_Y)\n",
    "    Y_pred = rfc.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, Y_pred)\n",
    "    t2 = time.time()\n",
    "    print('acc:', acc)\n",
    "    print('using time:', t2 - t1, 'sec')\n",
    "    matrix = confusion_matrix(test_Y, Y_pred)    \n",
    "    print(matrix)\n",
    "    error = mean_squared_error(y_test, pred_rfc)\n",
    "    print(\"随机森林-均方差为：\\n\", error)\n",
    "    report = classification_report(test_Y, Y_pred)\n",
    "    print(report)\n",
    "    print('-' * 40)\n",
    "    # plot_confusion_matrix(matrix, label, True, 'RF Confusion matrix')\n",
    "RF(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d192fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# print(\"Random Forest Classifier\")\n",
    "# # n_estimators，表示选择多少棵树来构造随机森林；具体解释看《边学边练超系统掌握人工智机器学习算法 传智播客》\n",
    "# rfc = RandomForestClassifier(n_estimators=200)\n",
    "# rfc.fit(X_train, y_train)\n",
    "# pred_rfc = rfc.predict(X_test)\n",
    "# print(\"Random Forest classification_report==\\n\",\n",
    "#       classification_report(y_test, pred_rfc))\n",
    "# print(\"Random Forest confusion_matrix==\\n\",\n",
    "#       confusion_matrix(y_test, pred_rfc))\n",
    "# error = mean_squared_error(y_test, pred_rfc)\n",
    "# print(\"随机森林-均方差为：\\n\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b898905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def SVM(train_X, train_Y, test_X, test_Y):\n",
    "    print('[SVM] train ...')\n",
    "    # train_Y = [np.where(r == 1)[0][0] for r in train_Y]\n",
    "    # test_Y = [np.where(r == 1)[0][0] for r in test_Y]\n",
    "    t1 = time.time()\n",
    "    clf = SVC(decision_function_shape='ovr', max_iter=300, kernel='rbf')\n",
    "    model = clf.fit(train_X, train_Y)\n",
    "    y_hat = model.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, y_hat)\n",
    "    t2 = time.time()\n",
    "    print('acc:', acc)\n",
    "    print('using time:', t2 - t1, 'sec')\n",
    "    matrix = confusion_matrix(test_Y, y_hat)\n",
    "    print(matrix)\n",
    "    report = classification_report(test_Y, y_hat)\n",
    "    print(report)\n",
    "    error = mean_squared_error(y_test, y_hat)\n",
    "    print(\"SVM-均方误差为：\\n\", error)\n",
    "    print('-' * 20)\n",
    "    # plot_confusion_matrix(matrix, label, True, 'SVM Confusion matrix')\n",
    "SVM(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn import svm, metrics\n",
    "# print(\"SVM Classifier\")\n",
    "# svmc = svm.SVC()\n",
    "# svmc.fit(X_train, y_train)\n",
    "# pred_svmc = svmc.predict(X_test)\n",
    "# print(\"SVM classification_report==\\n\",\n",
    "#       classification_report(y_test, pred_svmc))\n",
    "# print(\"SVM classification_confusion_matrix==\\n\",\n",
    "#       confusion_matrix(y_test, pred_svmc))\n",
    "# error = mean_squared_error(y_test, pred_svmc)\n",
    "# print(\"SVM-均方误差为：\\n\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "def NaiveBayes(train_X, train_Y, test_X, test_Y):\n",
    "    print('[Naive Bayes] train ...')\n",
    "    # train_Y = [np.where(r == 1)[0][0] for r in train_Y]\n",
    "    # test_Y = [np.where(r == 1)[0][0] for r in test_Y]\n",
    "    t1 = time.time()\n",
    "    clf = BernoulliNB()\n",
    "    model = clf.fit(train_X, train_Y)\n",
    "    y_hat = model.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, y_hat)\n",
    "    t2 = time.time()\n",
    "    print('acc:', acc)\n",
    "    print('using time:', t2 - t1, 'sec')\n",
    "    matrix = confusion_matrix(test_Y, y_hat)\n",
    "    print(matrix)\n",
    "    report = classification_report(test_Y, y_hat)\n",
    "    print(report)\n",
    "    print('-' * 20)\n",
    "    # plot_confusion_matrix(matrix, label, True, 'NB Confusion matrix')\n",
    "NaiveBayes(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "642190a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] train ...\n",
      "acc: 0.997340317537662\n",
      "using time: 145.4353985786438 sec\n",
      "[[48587     8]\n",
      " [  123   536]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     48595\n",
      "           1       0.99      0.81      0.89       659\n",
      "\n",
      "    accuracy                           1.00     49254\n",
      "   macro avg       0.99      0.91      0.94     49254\n",
      "weighted avg       1.00      1.00      1.00     49254\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#神经网络\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def MLP(train_X, train_Y, test_X, test_Y):\n",
    "    print('[MLP] train ...')\n",
    "    t1 = time.time()\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                          activation='logistic',\n",
    "                          solver='adam',\n",
    "                          learning_rate_init=0.0001,\n",
    "                          max_iter=2000)\n",
    "    model.fit(train_X, train_Y)\n",
    "    y_hat = model.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, y_hat)\n",
    "    t2 = time.time()\n",
    "    print('acc:', acc)\n",
    "    print('using time:', t2 - t1, 'sec')\n",
    "    matrix = confusion_matrix(test_Y, y_hat)\n",
    "    print(matrix)\n",
    "    report = classification_report(test_Y, y_hat)\n",
    "    print(report)\n",
    "    print('-' * 20)\n",
    "    # plot_confusion_matrix(matrix, label, True, 'MLP Confusion matrix')\n",
    "MLP(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73c3083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9991675802980469\n",
      "using time: 1.0644662380218506 sec\n",
      "[[48589     6]\n",
      " [   35   624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     48595\n",
      "           1       0.99      0.95      0.97       659\n",
      "\n",
      "    accuracy                           1.00     49254\n",
      "   macro avg       0.99      0.97      0.98     49254\n",
      "weighted avg       1.00      1.00      1.00     49254\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DT(train_X, train_Y, test_X, test_Y):\n",
    "    t1 = time.time()\n",
    "    clf = DecisionTreeClassifier(max_depth=6)\n",
    "    model = clf.fit(train_X, train_Y)\n",
    "    y_hat = model.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, y_hat)\n",
    "    t2 = time.time()\n",
    "    print('acc:', acc)\n",
    "    print('using time:', t2 - t1, 'sec')\n",
    "    matrix = confusion_matrix(test_Y, y_hat)\n",
    "    print(matrix)\n",
    "    report = classification_report(test_Y, y_hat)\n",
    "    print(report)\n",
    "    print('-' * 20)\n",
    "    # plot_confusion_matrix(matrix, label, True, 'DT Confusion matrix')\n",
    "DT(X_train,y_train,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
